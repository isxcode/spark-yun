---
title: "计算引擎排查"
---

#### 问题1

> spark local模式无法启动节点

查看至轻云日志

```bash
cd /opt/zhiqingyun/logs
tail -f spark-yun.log
```

查看至轻云节点日志

```bash
cd ~/zhiqingyun-agent/logs
tail -f zhiqingyun-agent.log
```

#### 问题2

![20241206175108](https://img.isxcode.com/picgo/20241206175108.png)

```log
如果spark的worker无法启动
```

> 请检查服务器中安装的是jre还是jdk，要安装jdk
> sudo yum install java-1.8.0-openjdk-devel java-1.8.0-openjdk -y

```bash
cd ~/zhiqingyun-agent/spark-min/sbin
bash start-worker.sh --webui-port 8081 spark://localhost:7077
```

#### 问题3

> 默认安装spark无法启动

```bash
cd ~/zhiqingyun-agent/spark-min/sbin
bash start-master.sh --webui-port 30170 --host localhost --port 30166
bash start-worker.sh --webui-port 30168 --host localhost --port 30169 -c 12 -m 20g spark://localhost:30166 

# 停止服务
bash stop-master.sh
bash stop-worker.sh
```

> 修改spark配置

```bash
vim ~/zhiqingyun-agent/spark-min/conf/spark-defaults.conf
```

```bash
spark.master          spark://localhost:30166
spark.master.web.url  http://localhost:30170
```

- master启动说明

```bash
Options:
-i HOST, --ip HOST     Hostname to listen on (deprecated, please use --host or -h) 
-h HOST, --host HOST   Hostname to listen on
-p PORT, --port PORT   Port to listen on (default: 7077)
--webui-port PORT      Port for web UI (default: 8080)
--properties-file FILE Path to a custom Spark properties file.
                       Default is conf/spark-defaults.conf.
```

- worker启动说明

```bash
Options:
-c CORES, --cores CORES  Number of cores to use
-m MEM, --memory MEM     Amount of memory to use (e.g. 1000M, 2G)
-d DIR, --work-dir DIR   Directory to run apps in (default: SPARK_HOME/work)
-i HOST, --ip IP         Hostname to listen on (deprecated, please use --host or -h)
-h HOST, --host HOST     Hostname to listen on
-p PORT, --port PORT     Port to listen on (default: random)
--webui-port PORT        Port for web UI (default: 8081)
--properties-file FILE   Path to a custom Spark properties file.
                         Default is conf/spark-defaults.conf. 
```

#### 问题4

> standalone模式资源不足

```log
standalone中的内存和核心都是虚拟的,可以通过修改配置扩大内存和核心数。
```

```bash
vim ~/zhiqingyun-agent/spark-min/conf/spark-env.sh
```

```bash
EXPORT SPARK_WORKER_CORES=32 # 最多可配置当前内存数*2，比如16GB内存，可配置16*2个虚拟核心
EXPORT SPARK_WORKER_MEMORY=32g # 最多可配置当前的内存数*2，比如16GB的内存，可配置16*2个虚拟内存
```