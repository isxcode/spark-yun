---
title: "实时计算"
---

#### 查看实时计算

> 基于Spark Streaming对实时数据进行同步转换 

![20241220165226](https://img.isxcode.com/picgo/20241220165226.png)

> 操作支持`提交日志`、`运行日志`、`编辑`、`运行`、`停止`、`删除`操作

- **提交日志**: 查看实时计算的提交日志 
- **运行日志**: 查看实时计算同步的条数 
- **编辑**: 编辑实时计算的备注和计算集群信息 
- **运行**: 运行实时计算 
- **停止**: 停止实时计算 
- **删除**: 删除实时计算

##### 查看运行日志，查看实时计算的条数

![20241220165549](https://img.isxcode.com/picgo/20241220165549.png)

#### 新增实时计算

> 点击`添加实时`，创建实时计算

![20241220165204](https://img.isxcode.com/picgo/20241220165204.png)

- **名称**: 必填，租户内名称唯一 
- **计算集群**: 必填，指定需要提交实时计算运行的计算集群 
- **备注**: 非必填

#### 新增Kafka实时计算

![20241220170936](https://img.isxcode.com/picgo/20241220170936.png)

> 第一步，选择kafka类型，选择kafka数据源   
> 第二步，复制kafka中传递的json结构体模版   
> 第三步，选择解析的`对象节点`类型   
> 第四步，选择目标数据源和目标表   
> 第五步，连接字段映射关系和字段转换函数   
> 第六步，点击运行按钮

#### 新增数据库实时同步

![20241220171300](https://img.isxcode.com/picgo/20241220171300.png)

> 第一步，选择非kafka的数据源类型，选择来源数据源，选择来源表   
> 第二步，选择kafka数据源，kafka数据源参考文档：   
> https://ispong.isxcode.com/hadoop/spark/spark%20debezium%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5/   
> 第三步，选择Cat的数据库表变化监听操作，支持`更新`、`删除`、`插入`  
> 第四步，选择目标数据源和目标表   
> 第五步，连接字段映射关系和字段转换函数   
> 第六步，点击运行按钮  